{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arm:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "    \n",
    "    def pull(self):\n",
    "        return np.random.binomial(1, self.p)\n",
    "\n",
    "class MultiBandit:\n",
    "    def __init__(self, probs = [0.1, 0.2, 0.7, 0.5]):\n",
    "        self.__arms = [Arm(p) for p in probs]\n",
    "        self.__regret = 0\n",
    "        self.__maxp = max(probs)\n",
    "\n",
    "    def num_arms(self):\n",
    "        return len(self.__arms)\n",
    "\n",
    "    def pull(self, arm_num):\n",
    "        reward = self.__arms[arm_num].pull()\n",
    "        self.__regret += self.__maxp-self.__arms[arm_num].p\n",
    "        return reward\n",
    "    \n",
    "    def regret(self):\n",
    "        return self.__regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyAlgorithm:\n",
    "    def __init__(self, num_arms, horizon, epsilon):\n",
    "        # Initialize our algorithm\n",
    "        self.num_arms = num_arms                    # Number of arms present in the bandit\n",
    "        self.horizon = horizon                      # Total Horizon of the algorithm\n",
    "        self.epsilon = epsilon                      # epsiolon value for the algorithm\n",
    "        self.timestep = 0                           # The current timestep while running the algorithm\n",
    "        self.arm_pulls = np.zeros(num_arms)         # History of number of times each arm was pulled\n",
    "        self.arm_rewards = np.zeros(num_arms)       # History of the total reward accumulated by each arm\n",
    "        self.regrets = np.zeros(horizon)            # Total regret at each timestep of the horizon\n",
    "\n",
    "    def give_best_arm(self):\n",
    "        # Return the arm which the algorithm considers to be the best arm at end of algorithm\n",
    "        pass\n",
    "\n",
    "    def select_arm(self):\n",
    "        # Select arm at each time step. You are supposed to return the index of which \n",
    "        # arm has been selected to pull at this timestep\n",
    "        pass\n",
    "\n",
    "    def run_algorithm(self, bandit):\n",
    "        # This is the proper algorithm. Already completed\n",
    "        for _ in range(self.horizon):\n",
    "            arm_to_pull = self.select_arm()             # Select the arm using the algorithm\n",
    "            reward = bandit.pull(arm_to_pull)           # Pull the arm and find our the reward\n",
    "            self.arm_pulls[arm_to_pull] += 1            # Update the arm pull count and arm reward count\n",
    "            self.arm_rewards[arm_to_pull] += reward\n",
    "            self.timestep += 1                          # Update the timestep\n",
    "            self.regrets[_] = bandit.regret()           # Store the regret values at each timestep\n",
    "    \n",
    "    def plot(self):\n",
    "        # Plot the regret graph. Label the X and Y Axis properly using matplotlib library\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a MultiBandit instance\n",
    "bandit = MultiBandit()\n",
    "# bandit = MultiBandit([0.1, 0.5, 0.8, 0.3, 0.4])   # Make custom Multi-armed Bandit. Should work while grading code\n",
    "\n",
    "# Set the horizon size\n",
    "H = 100\n",
    "\n",
    "# Create  Algorithm instance\n",
    "algorithm = EpsilonGreedyAlgorithm(num_arms=bandit.num_arms(), horizon=H, epsilon=0.2)\n",
    "\n",
    "# Run the algorithm\n",
    "algorithm.run_algorithm(bandit)\n",
    "\n",
    "# Display total regret\n",
    "print(f\"Total Regret after {H} timesteps: {bandit.regret()} with assumed best arm {algorithm.give_best_arm()}\")\n",
    "algorithm.plot()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
